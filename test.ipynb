{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99603d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean accuracies:\n",
      "  w=0.5: 0.7533\n",
      "  w=1.0: 0.7533\n",
      "  w=2.0: 0.7533\n",
      "  w=5.0: 0.7533\n",
      "Best w: 0.5\n",
      "Example predictions: [2 0 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from typing import Callable, Iterable, Any, Dict, Tuple\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score\n",
    "\n",
    "def tune_and_train_1nn(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    metric_func: Callable[[np.ndarray, np.ndarray, Any], float],\n",
    "    w_candidates: Iterable[Any],\n",
    "    k: int = 5,\n",
    "    stratify: bool = True,\n",
    "    random_state: int | None = None,\n",
    "    n_jobs: int = 1,\n",
    ") -> Tuple[KNeighborsClassifier, Any, Dict[Any, float]]:\n",
    "    \"\"\"\n",
    "    Tune hyperparameter w for a custom distance metric d(a,b,w) using k-fold CV,\n",
    "    then fit a 1-NN classifier with the chosen w.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : (n_samples, n_features) array\n",
    "    y : (n_samples,) array of labels\n",
    "    metric_func : callable(a, b, w) -> float\n",
    "        Black-box distance between two 1-D vectors a and b, using hyperparam w.\n",
    "    w_candidates : iterable of candidate w values\n",
    "    k : number of folds for CV (default 5)\n",
    "    stratify : whether to use StratifiedKFold when possible\n",
    "    random_state : int or None for CV shuffling\n",
    "    n_jobs : number of jobs for CV (set to 1 to avoid pickling issues with some callables)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clf_best : fitted KNeighborsClassifier (n_neighbors=1) using best w\n",
    "    best_w : chosen hyperparameter\n",
    "    cv_results : dict mapping w -> mean CV accuracy\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be 2D: (n_samples, n_features)\")\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"X and y must have same number of samples\")\n",
    "\n",
    "    # choose CV splitter\n",
    "    if stratify and len(np.unique(y)) > 1:\n",
    "        cv_splitter = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    else:\n",
    "        cv_splitter = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    cv_results = {}\n",
    "    # IMPORTANT: use n_jobs=1 here by default because cross_val_score may pickle the callable metric.\n",
    "    # If your metric and environment are picklable, you can set n_jobs > 1.\n",
    "    for w in w_candidates:\n",
    "        # create a callable metric that binds w\n",
    "        bound_metric = lambda a, b, w=w: metric_func(a, b, w)\n",
    "        # KNeighborsClassifier accepts a callable metric; this will use brute-force search\n",
    "        clf = KNeighborsClassifier(n_neighbors=1, metric=bound_metric, algorithm='brute')\n",
    "        scores = cross_val_score(clf, X, y, cv=cv_splitter, scoring='accuracy', n_jobs=n_jobs)\n",
    "        cv_results[w] = float(np.mean(scores))\n",
    "\n",
    "    # pick best w (max mean accuracy). tie -> first encountered in w_candidates\n",
    "    best_w = max(w_candidates, key=lambda w: cv_results[w])\n",
    "\n",
    "    # fit final classifier on entire data with the chosen w\n",
    "    best_metric = lambda a, b, w=best_w: metric_func(a, b, w)\n",
    "    clf_best = KNeighborsClassifier(n_neighbors=1, metric=best_metric, algorithm='brute')\n",
    "    clf_best.fit(X, y)\n",
    "\n",
    "    return clf_best, best_w, cv_results\n",
    "\n",
    "# -----------------------\n",
    "# Example usage\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "\n",
    "    # example: weighted euclidean metric where w is a scalar weight or vector of per-feature weights\n",
    "    def weighted_euclidean(a, b, w):\n",
    "        a = np.asarray(a); b = np.asarray(b)\n",
    "        if np.isscalar(w):\n",
    "            wvec = np.full(a.shape, w)\n",
    "        else:\n",
    "            wvec = np.asarray(w)\n",
    "            if wvec.shape != a.shape:\n",
    "                raise ValueError(\"w must be scalar or same shape as vectors\")\n",
    "        diff = (a - b) * wvec\n",
    "        return np.linalg.norm(diff)\n",
    "\n",
    "    X, y = make_classification(n_samples=300, n_features=5, n_informative=3,\n",
    "                               n_redundant=0, n_classes=3, random_state=0)\n",
    "\n",
    "    w_candidates = [0.5, 1.0, 2.0, 5.0]\n",
    "    clf, best_w, results = tune_and_train_1nn(X, y, weighted_euclidean, w_candidates,\n",
    "                                              k=5, stratify=True, random_state=0, n_jobs=1)\n",
    "\n",
    "    print(\"CV mean accuracies:\")\n",
    "    for w, acc in results.items():\n",
    "        print(f\"  w={w}: {acc:.4f}\")\n",
    "    print(\"Best w:\", best_w)\n",
    "    print(\"Example predictions:\", clf.predict(X[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af17805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation of 5 candidates on 3 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV results (w -> mean accuracy):\n",
      "  0.2: 0.7162\n",
      "  0.5: 0.7162\n",
      "  1.0: 0.7162\n",
      "  2.0: 0.7162\n",
      "  5.0: 0.7162\n",
      "Best w: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:00<00:00, 467.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example predictions (first 10): [3 0 1 0 0 3 3 1 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Callable, Iterable, Any, Dict, Tuple, List\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# ---- module-level globals for worker processes (set via initializer) ----\n",
    "_METRIC_FUNC = None\n",
    "_X = None\n",
    "_Y = None\n",
    "_K = None\n",
    "_RANDOM_STATE = None\n",
    "\n",
    "def _worker_init(metric_func, X, y, k, random_state):\n",
    "    \"\"\"Initializer for worker processes: set globals once per worker.\"\"\"\n",
    "    global _METRIC_FUNC, _X, _Y, _K, _RANDOM_STATE\n",
    "    _METRIC_FUNC = metric_func\n",
    "    _X = X\n",
    "    _Y = y\n",
    "    _K = k\n",
    "    _RANDOM_STATE = random_state\n",
    "\n",
    "def _evaluate_w(w) -> Tuple[Any, float]:\n",
    "    \"\"\"\n",
    "    Worker: evaluate one w via KFold CV (plain KFold since labels are balanced).\n",
    "    Returns (w, mean_accuracy).\n",
    "    \"\"\"\n",
    "    global _METRIC_FUNC, _X, _Y, _K, _RANDOM_STATE\n",
    "    cv = KFold(n_splits=_K, shuffle=True, random_state=_RANDOM_STATE)\n",
    "    scores: List[float] = []\n",
    "    for train_idx, val_idx in cv.split(_X):\n",
    "        X_tr, y_tr = _X[train_idx], _Y[train_idx]\n",
    "        X_val, y_val = _X[val_idx], _Y[val_idx]\n",
    "\n",
    "        correct = 0\n",
    "        for xi, yi in zip(X_val, y_val):\n",
    "            # brute-force distances (metric must be picklable and top-level)\n",
    "            dists = [float(_METRIC_FUNC(xi, xt, w)) for xt in X_tr]\n",
    "            nn = int(np.argmin(dists))\n",
    "            if y_tr[nn] == yi:\n",
    "                correct += 1\n",
    "        scores.append(correct / len(y_val))\n",
    "    return (w, float(np.mean(scores)))\n",
    "\n",
    "def tune_and_train_1nn_parallel(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    metric_func: Callable[[np.ndarray, np.ndarray, Any], float],\n",
    "    w_candidates: Iterable[Any],\n",
    "    k: int = 5,\n",
    "    random_state: int | None = None,\n",
    "    n_procs: int = 8,\n",
    "    verbose: bool = True,\n",
    ") -> Tuple[KNeighborsClassifier, Any, Dict[Any, float]]:\n",
    "    \"\"\"\n",
    "    Parallel search over w_candidates using multiprocessing.Pool and KFold CV.\n",
    "    Returns: (fitted_1nn_classifier, best_w, cv_results_dict)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    w_list = list(w_candidates)\n",
    "    if len(w_list) == 0:\n",
    "        raise ValueError(\"w_candidates must be non-empty\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Starting evaluation of {len(w_list)} candidates on {n_procs} processes...\")\n",
    "\n",
    "    init_args = (metric_func, X, y, k, random_state)\n",
    "    with Pool(processes=n_procs, initializer=_worker_init, initargs=init_args) as pool:\n",
    "        results_iter = pool.imap(_evaluate_w, w_list)\n",
    "        results = list(tqdm(results_iter, total=len(w_list)))\n",
    "\n",
    "    cv_results: Dict[Any, float] = {w: acc for (w, acc) in results}\n",
    "    # pick best w (highest mean accuracy); tie -> first in w_list order\n",
    "    best_w = max(w_list, key=lambda w: cv_results[w])\n",
    "\n",
    "    # final classifier on full data using chosen best_w\n",
    "    def bound_metric(a, b, w=best_w):\n",
    "        return metric_func(a, b, w)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=1, metric=bound_metric, algorithm='brute')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"CV results (w -> mean accuracy):\")\n",
    "        for w in w_list:\n",
    "            print(f\"  {w}: {cv_results[w]:.4f}\")\n",
    "        print(\"Best w:\", best_w)\n",
    "\n",
    "    return clf, best_w, cv_results\n",
    "\n",
    "# -----------------------\n",
    "# Example usage\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "\n",
    "    # Example metric (top-level function so it's picklable)\n",
    "    def weighted_euclidean(a, b, w):\n",
    "        a = np.asarray(a); b = np.asarray(b)\n",
    "        if np.isscalar(w):\n",
    "            wvec = np.full(a.shape, float(w))\n",
    "        else:\n",
    "            wvec = np.asarray(w, dtype=float)\n",
    "            if wvec.shape != a.shape:\n",
    "                raise ValueError(\"w must be scalar or same shape as input vectors\")\n",
    "        diff = (a - b) * wvec\n",
    "        return float(np.linalg.norm(diff))\n",
    "\n",
    "    # Synthetic balanced dataset\n",
    "    X, y = make_classification(n_samples=800, n_features=8, n_informative=6,\n",
    "                               n_redundant=0, n_classes=4, weights=None, random_state=0)\n",
    "\n",
    "    w_candidates = [0.2, 0.5, 1.0, 2.0, 5.0]\n",
    "    clf, best_w, cv_results = tune_and_train_1nn_parallel(\n",
    "        X, y, weighted_euclidean, w_candidates,\n",
    "        k=5, random_state=0, n_procs=3, verbose=True\n",
    "    )\n",
    "\n",
    "    # Optional: parallel predictions per-sample using the same imap pattern\n",
    "    # (keeps your syntax: with Pool(...); pool.imap(...))\n",
    "    def _pred_worker_init(classifier):\n",
    "        global _PRED_CLF\n",
    "        _PRED_CLF = classifier\n",
    "\n",
    "    def _predict_single(x):\n",
    "        global _PRED_CLF\n",
    "        return int(_PRED_CLF.predict([x])[0])\n",
    "\n",
    "    X_test = X[:200]\n",
    "    with Pool(processes=3, initializer=_pred_worker_init, initargs=(clf,)) as pool:\n",
    "        y_pred_list = list(tqdm(pool.imap(_predict_single, X_test), total=len(X_test)))\n",
    "    y_pred = np.array(y_pred_list)\n",
    "\n",
    "    print(\"Example predictions (first 10):\", y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2baafa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "global x \n",
    "\n",
    "def fun():\n",
    "    print(x)\n",
    "x = 100\n",
    "fun_copy = fun\n",
    "fun_copy()\n",
    "for i in range(10):\n",
    "    x = i\n",
    "    fun_copy()\n",
    "    fun()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
